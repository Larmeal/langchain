{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the Gemini-Pro\n",
    "\n",
    "Vertex AI: https://ai.google.dev/gemini-api/docs/get-started/tutorial?lang=python\n",
    "\n",
    "LangChain: https://python.langchain.com/v0.1/docs/integrations/chat/google_generative_ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain the quantum mechanic in one sentence\"\n",
    "result = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum mechanics is a branch of science that studies the behavior of matter and energy at the atomic and subatomic levels, where classical mechanics fails to explain their behavior.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\armlo\\anaconda3\\envs\\langchain\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:345: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are the Physicist and only response the output in Thai language only\"),\n",
    "    HumanMessage(content=prompt)\n",
    "]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\", convert_system_message_to_human=True)\n",
    "result = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'กลศาสตร์ควอนตัมอธิบายพฤติกรรมของสสารและพลังงานในระดับอะตอมและอนุภาคมูลฐาน'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching LLM Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Memory Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me a some dad jokes in two examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What do you call a fish with no eyes? Fsh!\n",
      "2. Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "3. What do you call a belt made out of watches? A waist of time!\n",
      "4. Why did the golfer wear two pairs of pants? In case he got a hole-in-one!\n",
      "5. What do you call a lazy kangaroo? A pouch potato!\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What do you call a fish with no eyes? Fsh!\n",
      "2. Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "3. What do you call a belt made out of watches? A waist of time!\n",
      "4. Why did the golfer wear two pairs of pants? In case he got a hole-in-one!\n",
      "5. What do you call a lazy kangaroo? A pouch potato!\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 999 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLite Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\"./langchain.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 1.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"1. What do you call a boomerang that doesn't come back? A stick!\\n2. Why did the scarecrow win an award? Because he was outstanding in his field!\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-c82ab426-75c2-4398-b648-25c99ada289a-0', usage_metadata={'input_tokens': 10, 'output_tokens': 39, 'total_tokens': 49})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 14.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"1. What do you call a boomerang that doesn't come back? A stick!\\n2. Why did the scarecrow win an award? Because he was outstanding in his field!\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-c82ab426-75c2-4398-b648-25c99ada289a-0', usage_metadata={'input_tokens': 10, 'output_tokens': 39, 'total_tokens': 49})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "prompt = \"Tell me a chorus lyrics of 'talking to the moon' of Bruno mars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Talking to the moon\n",
      "Trying to get to you\n",
      "In hopes you're on the other side\n",
      "Talking to me too\n",
      "Or am I a fool\n",
      "Who's trying to catch the moon"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    You are the expert virologist.\n",
    "    Write a few sentence to explain about the {virus} in {language} language.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    You are the expert virologist.\\n    Write a few sentence to explain about the HIV in Thai language.\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.format(virus=\"HIV\", language=\"Thai\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HIV (Human Immunodeficiency Virus) เป็นไวรัสที่ทำลายเซลล์เม็ดเลือดขาวชนิดหนึ่ง ทำให้ร่างกายอ่อนแอและติดเชื้อได้ง่าย หากไม่ได้รับการรักษา HIV อาจลุกลามไปเป็นโรคเอดส์ (Acquired Immunodeficiency Syndrome) ซึ่งเป็นระยะสุดท้ายของการติดเชื้อ HIV'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain ChatPromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\", convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You have to response array in JSON format\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"Top {n} countries at {continent} order by population\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(n=10, continent=\"asia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\armlo\\anaconda3\\envs\\langchain\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:345: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    }
   ],
   "source": [
    "output = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"country\": \"China\",\n",
      "    \"population\": 1,444,244,680\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"India\",\n",
      "    \"population\": 1,393,409,038\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Indonesia\",\n",
      "    \"population\": 273,523,615\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Pakistan\",\n",
      "    \"population\": 220,892,340\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Bangladesh\",\n",
      "    \"population\": 164,689,383\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Japan\",\n",
      "    \"population\": 126,440,000\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Philippines\",\n",
      "    \"population\": 109,581,078\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Vietnam\",\n",
      "    \"population\": 97,338,583\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Thailand\",\n",
      "    \"population\": 69,799,924\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Myanmar\",\n",
      "    \"population\": 54,409,794\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Chained Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    You are the expert virologist.\n",
    "    Write a few sentence to explain about the {virus} in {language} language.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are the expert virologist.\n",
      "    Write a few sentence to explain about the HIV in Thai language.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "output = chain.invoke({\"virus\": \"HIV\", \"language\": \"Thai\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'virus': 'HIV',\n",
       " 'language': 'Thai',\n",
       " 'text': 'เชื้อ HIV เป็นเชื้อไวรัสที่ทำลายเซลล์เม็ดเลือดขาวชนิด CD4 ซึ่งเป็นเซลล์ที่สำคัญในระบบภูมิคุ้มกันของร่างกาย เมื่อร่างกายมีปริมาณเซลล์ CD4 ต่ำลง ระบบภูมิคุ้มกันก็จะอ่อนแอลง ทำให้เสี่ยงต่อการติดเชื้อฉวยโอกาสหรือโรคมะเร็งได้ง่ายขึ้น'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Squential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_google_genai import GoogleGenerativeAI\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain, SimpleSequentialChain, SequentialChain\n",
    "\n",
    "\n",
    "# llm1 = GoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "# llm2 = GoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template1 = PromptTemplate.from_template(\n",
    "#     template = \"\"\"You are the expert virologist.\n",
    "#     Write a few sentence to explain about the {virus}\"\"\"\n",
    "# )\n",
    "\n",
    "# prompt_template2 = PromptTemplate.from_template(\n",
    "#     template = \"\"\"Convert the contents to {language}\"\"\"\n",
    "# )\n",
    "\n",
    "# chain1 = LLMChain(llm=llm1, prompt=prompt_template1.format(virus=\"HIV\"))\n",
    "# chain2 = LLMChain(llm=llm2, prompt=prompt_template2.format(language=\"Thai\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "# output = overall.invoke(\"virus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
