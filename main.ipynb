{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the Gemini-Pro\n",
    "\n",
    "Vertex AI: https://ai.google.dev/gemini-api/docs/get-started/tutorial?lang=python\n",
    "\n",
    "LangChain: https://python.langchain.com/v0.1/docs/integrations/chat/google_generative_ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain the quantum mechanic in one sentence\"\n",
    "result = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum mechanics is a branch of science that studies the behavior of matter and energy at the atomic and subatomic levels, where classical mechanics fails to explain their behavior.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\armlo\\anaconda3\\envs\\langchain\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:345: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are the Physicist and only response the output in Thai language only\"),\n",
    "    HumanMessage(content=prompt)\n",
    "]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\", convert_system_message_to_human=True)\n",
    "result = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'กลศาสตร์ควอนตัมอธิบายพฤติกรรมของสสารและพลังงานในระดับอะตอมและอนุภาคมูลฐาน'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching LLM Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Memory Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me a some dad jokes in two examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What do you call a fish with no eyes? Fsh!\n",
      "2. Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "3. What do you call a belt made out of watches? A waist of time!\n",
      "4. Why did the golfer wear two pairs of pants? In case he got a hole-in-one!\n",
      "5. What do you call a lazy kangaroo? A pouch potato!\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What do you call a fish with no eyes? Fsh!\n",
      "2. Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "3. What do you call a belt made out of watches? A waist of time!\n",
      "4. Why did the golfer wear two pairs of pants? In case he got a hole-in-one!\n",
      "5. What do you call a lazy kangaroo? A pouch potato!\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 999 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLite Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\"./langchain.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 1.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"1. What do you call a boomerang that doesn't come back? A stick!\\n2. Why did the scarecrow win an award? Because he was outstanding in his field!\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-c82ab426-75c2-4398-b648-25c99ada289a-0', usage_metadata={'input_tokens': 10, 'output_tokens': 39, 'total_tokens': 49})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 14.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"1. What do you call a boomerang that doesn't come back? A stick!\\n2. Why did the scarecrow win an award? Because he was outstanding in his field!\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-c82ab426-75c2-4398-b648-25c99ada289a-0', usage_metadata={'input_tokens': 10, 'output_tokens': 39, 'total_tokens': 49})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "prompt = \"Tell me a chorus lyrics of 'talking to the moon' of Bruno mars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Talking to the moon\n",
      "Trying to get to you\n",
      "In hopes you're on the other side\n",
      "Talking to me too\n",
      "Or am I a fool\n",
      "Who's trying to catch the moon"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    You are the expert virologist.\n",
    "    Write a few sentence to explain about the {virus} in {language} language.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    You are the expert virologist.\\n    Write a few sentence to explain about the HIV in Thai language.\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.format(virus=\"HIV\", language=\"Thai\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HIV (Human Immunodeficiency Virus) เป็นไวรัสที่ทำลายเซลล์เม็ดเลือดขาวชนิดหนึ่ง ทำให้ร่างกายอ่อนแอและติดเชื้อได้ง่าย หากไม่ได้รับการรักษา HIV อาจลุกลามไปเป็นโรคเอดส์ (Acquired Immunodeficiency Syndrome) ซึ่งเป็นระยะสุดท้ายของการติดเชื้อ HIV'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain ChatPromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\", convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You have to response array in JSON format\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"Top {n} countries at {continent} order by population\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(n=10, continent=\"asia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\armlo\\anaconda3\\envs\\langchain\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:345: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    }
   ],
   "source": [
    "output = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"country\": \"China\",\n",
      "    \"population\": 1,444,244,680\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"India\",\n",
      "    \"population\": 1,393,409,038\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Indonesia\",\n",
      "    \"population\": 273,523,615\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Pakistan\",\n",
      "    \"population\": 220,892,340\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Bangladesh\",\n",
      "    \"population\": 164,689,383\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Japan\",\n",
      "    \"population\": 126,440,000\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Philippines\",\n",
      "    \"population\": 109,581,078\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Vietnam\",\n",
      "    \"population\": 97,338,583\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Thailand\",\n",
      "    \"population\": 69,799,924\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Myanmar\",\n",
      "    \"population\": 54,409,794\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Chained Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    You are the expert virologist.\n",
    "    Write a few sentence to explain about the {virus} in {language} language.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are the expert virologist.\n",
      "    Write a few sentence to explain about the HIV in Thai language.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "output = chain.invoke({\"virus\": \"HIV\", \"language\": \"Thai\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'virus': 'HIV',\n",
       " 'language': 'Thai',\n",
       " 'text': 'เชื้อ HIV เป็นเชื้อไวรัสที่ทำลายเซลล์เม็ดเลือดขาวชนิด CD4 ซึ่งเป็นเซลล์ที่สำคัญในระบบภูมิคุ้มกันของร่างกาย เมื่อร่างกายมีปริมาณเซลล์ CD4 ต่ำลง ระบบภูมิคุ้มกันก็จะอ่อนแอลง ทำให้เสี่ยงต่อการติดเชื้อฉวยโอกาสหรือโรคมะเร็งได้ง่ายขึ้น'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Squential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_google_genai import GoogleGenerativeAI\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain, SimpleSequentialChain, SequentialChain\n",
    "\n",
    "\n",
    "# llm1 = GoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "# llm2 = GoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template1 = PromptTemplate.from_template(\n",
    "#     template = \"\"\"You are the expert virologist.\n",
    "#     Write a few sentence to explain about the {virus}\"\"\"\n",
    "# )\n",
    "\n",
    "# prompt_template2 = PromptTemplate.from_template(\n",
    "#     template = \"\"\"Convert the contents to {language}\"\"\"\n",
    "# )\n",
    "\n",
    "# chain1 = LLMChain(llm=llm1, prompt=prompt_template1.format(virus=\"HIV\"))\n",
    "# chain2 = LLMChain(llm=llm2, prompt=prompt_template2.format(language=\"Thai\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "# output = overall.invoke(\"virus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python REPL for Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=API_KEY, model=\"gemini-pro\")\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
      "Action Input: print(round(pow(math.factorial(12), 1/3), 4))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNameError(\"name 'math' is not defined\")\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
      "Action Input: import math\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
      "Action Input: print(round(pow(math.factorial(12), 1/3), 4))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m782.4303\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 782.4303\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Calculate the 3rd root of the factorial of 12 and display it with 4 decimal points',\n",
       " 'output': '782.4303'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Calculate the 3rd root of the factorial of 12 and display it with 4 decimal points\"\n",
    "agent_executor.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DuckDuckGo for Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.tools import DuckDuckGoSearchResults, DuckDuckGoSearchRun, tavily_search\n",
    "from langchain_community.tools.ddg_search.tool import DuckDuckGoSearchRun, DuckDuckGoSearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchRun()\n",
    "search_results = DuckDuckGoSearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git is a version control system that tracks file changes and GitHub is a platform that allows developers to collaborate and store their code in the cloud. Think of it this way: Git is responsible for everything GitHub-related that happens locally on your computer. They both work together to make building, scaling, securing, and storing software ... What is Git? Git is a distributed version control system designed to handle everything from small to very large projects with speed and efficiency. It was created by Linus Torvalds in 2005 for the development of the Linux kernel. In this article, we will discuss about Git, its features, advantages, and disadvantages. Learn what Git is, how to install and configure it, and how to use its basic commands to create, commit, and sync repositories. This guide covers the essential concepts and workflows of Git for developers. Git offers a variety of configurations that can streamline your workflow. In this section, I will guide you through the process of setting up Git on your local machine. Let's get started. Configuring your name and email address on your local machine is an essential step in setting up Git. These details are attached to each commit you make ... Git is a distributed version control system and source code management system.It is designed to handle everything from small to very large projects with speed and efficiency. Git allows multiple developers to work on the same project without overwriting each other's changes, providing collaborative work and continuous integration and deployment.\n"
     ]
    }
   ],
   "source": [
    "response = search.run(\"What is Git?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[snippet: Git is a version control system that tracks file changes and GitHub is a platform that allows developers to collaborate and store their code in the cloud. Think of it this way: Git is responsible for everything GitHub-related that happens locally on your computer. They both work together to make building, scaling, securing, and storing software ..., title: What is Git? Our beginner's guide to version control, link: https://github.blog/2024-05-27-what-is-git-our-beginners-guide-to-version-control/], [snippet: What is Git? Git is a distributed version control system designed to handle everything from small to very large projects with speed and efficiency. It was created by Linus Torvalds in 2005 for the development of the Linux kernel. In this article, we will discuss about Git, its features, advantages, and disadvantages., title: What is Git? - GeeksforGeeks, link: https://www.geeksforgeeks.org/what-is-git/], [snippet: Learn what Git is, how to install and configure it, and how to use its basic commands to create, commit, and sync repositories. This guide covers the essential concepts and workflows of Git for developers., title: Git for Beginners: The Definitive Practical Guide - Baeldung, link: https://www.baeldung.com/ops/git-guide], [snippet: Git offers a variety of configurations that can streamline your workflow. In this section, I will guide you through the process of setting up Git on your local machine. Let's get started. Configuring your name and email address on your local machine is an essential step in setting up Git. These details are attached to each commit you make ..., title: How to Use Git and GitHub - a Guide for Beginners and Experienced ..., link: https://www.freecodecamp.org/news/guide-to-git-github-for-beginners-and-experienced-devs/]\n"
     ]
    }
   ],
   "source": [
    "response = search_results.run(\"What is Git?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### Convert to string to JSON #######################################\n",
    "\n",
    "# import re\n",
    "# import json\n",
    "\n",
    "# # String pattern to be converted\n",
    "# # Function to convert string pattern to JSON format\n",
    "# def convert_to_json(data_string: str) -> json:\n",
    "#     # Regular expression to extract snippets, titles, and links\n",
    "#     pattern = re.compile(r'\\[snippet: (.*?), title: (.*?), link: (.*?)\\]')\n",
    "    \n",
    "#     # Finding all matches in the string\n",
    "#     matches = pattern.findall(data_string)\n",
    "    \n",
    "#     # Preparing the list of dictionaries\n",
    "#     json_list = []\n",
    "#     for match in matches:\n",
    "#         snippet, title, link = match\n",
    "#         entry_dict = {\n",
    "#             \"snippet\": snippet.strip(),\n",
    "#             \"title\": title.strip(),\n",
    "#             \"link\": link.strip()\n",
    "#         }\n",
    "#         json_list.append(entry_dict)\n",
    "    \n",
    "#     # Convert the list to JSON format\n",
    "#     json_output = json.dumps(json_list, indent=4)\n",
    "#     return json.loads(json_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tavily AI for Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.tools.tavily_search.tool import TavilyAnswer, TavilySearchResults\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilyAnswer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git is a distributed version control system that handles data as a stream of snapshots, making it distinct from other version control systems. It is known for its performance, security, flexibility, and support for branching, tagging, and nonlinear development workflows. As of the latest data available, Git is the most widely used source-code management tool, with significant adoption among professional software developers and open-source projects. It is favored by developers and has various extensions like Git LFS.\n"
     ]
    }
   ],
   "source": [
    "response = search.run(\"What is Git?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = search_results.run(\"What is Git?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://en.wikipedia.org/wiki/Git', 'content': \"SourceForge, Bitbucket and GitLab.[92][17][18][19][20]\\nAdoption[edit]\\nThe Eclipse Foundation reported in its annual community survey that as of May 2014, Git is now the most widely used source-code management tool, with 42.9% of professional software developers reporting that they use Git as their primary source-control system[93] compared with 36.3% in 2013, 32% in 2012; or for Git responses excluding use of GitHub: 33.3% in 2014, 30.3% in 2013, 27.6% in 2012 and 12.8% in 2011.[94] Open-source directory Black Duck Open Hub reports a similar uptake among open-source projects.[95]\\nStack Overflow has included version control in their annual developer survey[96] in 2015 (16,694 responses),[97] 2017 (30,730 responses),[98] 2018 (74,298 responses)[99] and 2022 (71,379 responses).[15] Git was the overwhelming favorite of responding developers in these surveys, reporting as high as 93.9% in 2022.\\n It has bindings for many programming languages, including Ruby, Python, and Haskell.[79][80][81]\\nJS-Git is a JavaScript implementation of a subset of Git.[82]\\nGameOfTrees is an open-source implementation of Git for the OpenBSD project.[83]\\nGit server[edit]\\nAs Git is a distributed version control system, it could be used as a server out of the box. If a Windows or Mac user pulls (downloads) a version of the repository with the malicious directory, then switches to that directory, the .git directory will be overwritten (due to the case-insensitive trait of the Windows and Mac filesystems) and the malicious executable files in .git/hooks may be run, which results in the attacker's commands being executed. Version control systems used by responding developers:\\nThe UK IT jobs website itjobswatch.co.uk reports that as of late September 2016, 29.27% of UK permanent software development job openings have cited Git,[100] ahead of 12.17% for Microsoft Team Foundation Server,[101] 10.60% for Subversion,[102] 1.30% for Mercurial,[103] and 0.48% for Visual SourceSafe.[104]\\nExtensions[edit]\\nThere are many Git extensions, like Git LFS, which started as an extension to Git in the GitHub community and is now widely used by other repositories. It is currently used for backing projects as a SQL interface for Git code repositories[75] and providing encryption for Git.[76]\\nThe Dulwich implementation of Git is a pure Python software component for Python 2.7, 3.4 and 3.5.[77]\\nThe libgit2 implementation of Git is an ANSI C software library with no other dependencies, which can be built on multiple platforms, including Windows, Linux, macOS, and BSD.[78]\"}\n"
     ]
    }
   ],
   "source": [
    "print(response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Owned ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import Tool, AgentExecutor, initialize_agent, create_react_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_community.tools.ddg_search.tool import DuckDuckGoSearchRun\n",
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleGenerativeAI(\n",
    "    google_api_key=API_KEY,\n",
    "    temperature=0,\n",
    "    model=\"gemini-1.5-pro\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the following question as best you can. \n",
    "Questions: {question} \n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
