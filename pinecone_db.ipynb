{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "PINECONE_KEY = os.getenv('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index...\n",
      "Creating Done!!\n"
     ]
    }
   ],
   "source": [
    "index_name = \"langchain\"\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    print(\"Creating index...\")\n",
    "    pc.create_index(\n",
    "        name=\"langchain\",\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "    print(\"Creating Done!!\")\n",
    "else:\n",
    "    print(f'The index: {index_name} is already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 0}},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"langchain\"\n",
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting index...\n",
      "Deleting Done!!\n"
     ]
    }
   ],
   "source": [
    "index_name = \"langchain\"\n",
    "if index_name in pc.list_indexes().names():\n",
    "    print(\"Deleting index...\")\n",
    "    pc.delete_index(index_name)\n",
    "    print(\"Deleting Done!!\")\n",
    "else:\n",
    "    print(f\"The index: {index_name} isn't already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work with Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsert Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "upserted_count: 5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "vector = [[random.random() for _ in range(1536)] for i in range(5)]\n",
    "\n",
    "ids = list(\"abcde\")\n",
    "index_name = \"langchain\"\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(vectors=zip(ids, vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': '', 'usage': {'read_units': 1}, 'vectors': {}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fetch(ids=[\"c\", \"d\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.delete(ids=[\"c\", \"d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': '', 'usage': {'read_units': 1}, 'vectors': {}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fetch(ids=[\"c\", \"d\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5472030443138011, 0.08824136968375529, 0.17353503121948954]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = [random.random() for _ in range(1536)]\n",
    "query[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [], 'namespace': '', 'usage': {'read_units': 1}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(\n",
    "    vector=query,\n",
    "    top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 0}},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "upserted_count: 3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "vector = [[random.random() for _ in range(1536)] for i in range(5)]\n",
    "\n",
    "ids = list(\"xyz\")\n",
    "index_name = \"langchain\"\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(vectors=zip(ids, vector), namespace=\"first-time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 0}, 'first-time': {'vector_count': 0}},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "upserted_count: 3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "vector = [[random.random() for _ in range(1536)] for i in range(5)]\n",
    "\n",
    "ids = list(\"opq\")\n",
    "index_name = \"langchain\"\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(vectors=zip(ids, vector), namespace=\"second-time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 3},\n",
       "                'first-time': {'vector_count': 0},\n",
       "                'second-time': {'vector_count': 0}},\n",
       " 'total_vector_count': 3}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 3},\n",
       "                'first-time': {'vector_count': 0},\n",
       "                'second-time': {'vector_count': 0}},\n",
       " 'total_vector_count': 3}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't define the namespace. It's not working because of wrong namespaces\n",
    "index.delete(ids=[\"o\"])\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 3},\n",
       "                'first-time': {'vector_count': 3},\n",
       "                'second-time': {'vector_count': 0}},\n",
       " 'total_vector_count': 6}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.delete(ids=[\"o\"], namespace=\"second-time\")\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 3}, 'second-time': {'vector_count': 0}},\n",
       " 'total_vector_count': 3}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.delete(delete_all=True, namespace=\"first-time\")\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the search similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear the old index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting index: medium\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "for name in pc.list_indexes().names():\n",
    "    if len(name) != 0:\n",
    "        print(f\"Deleting index: {name}\")\n",
    "        pc.delete_index(name=name)\n",
    "        print(\"Done!!\")\n",
    "    else:\n",
    "        print(\"Don't have any indexes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters.nltk import NLTKTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(f\"source/Python libraries take the Billion Row Challenge _ by Thomas Reid _ Level Up Coding.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(pages: list) -> str:\n",
    "    concat_pages = []\n",
    "    for page in pages:\n",
    "        text_splitter = NLTKTextSplitter()\n",
    "        document = text_splitter.split_text(page.page_content)\n",
    "        concat_pages.extend(document)\n",
    "\n",
    "    documents = \"\\n\".join(concat_pages)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = NLTKTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 333, which is longer than the specified 200\n",
      "Created a chunk of size 267, which is longer than the specified 200\n",
      "Created a chunk of size 269, which is longer than the specified 200\n",
      "Created a chunk of size 300, which is longer than the specified 200\n",
      "Created a chunk of size 222, which is longer than the specified 200\n",
      "Created a chunk of size 669, which is longer than the specified 200\n",
      "Created a chunk of size 291, which is longer than the specified 200\n",
      "Created a chunk of size 257, which is longer than the specified 200\n",
      "Created a chunk of size 478, which is longer than the specified 200\n",
      "Created a chunk of size 1115, which is longer than the specified 200\n",
      "Created a chunk of size 1391, which is longer than the specified 200\n",
      "Created a chunk of size 280, which is longer than the specified 200\n",
      "Created a chunk of size 1174, which is longer than the specified 200\n",
      "Created a chunk of size 243, which is longer than the specified 200\n",
      "Created a chunk of size 207, which is longer than the specified 200\n",
      "Created a chunk of size 785, which is longer than the specified 200\n",
      "Created a chunk of size 758, which is longer than the specified 200\n",
      "Created a chunk of size 1662, which is longer than the specified 200\n",
      "Created a chunk of size 845, which is longer than the specified 200\n",
      "Created a chunk of size 1286, which is longer than the specified 200\n",
      "Created a chunk of size 270, which is longer than the specified 200\n",
      "Created a chunk of size 701, which is longer than the specified 200\n",
      "Created a chunk of size 284, which is longer than the specified 200\n"
     ]
    }
   ],
   "source": [
    "documents = convert_data(pages)\n",
    "chucks = text_splitter.create_documents([documents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = (\n",
    "    OllamaEmbeddings(model=\"llama3\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_chucks = embeddings.embed_documents(chucks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Document to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "\n",
    "pc = pinecone.Pinecone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index...\n",
      "Creating Done!!\n"
     ]
    }
   ],
   "source": [
    "# Create the index in Pinecone\n",
    "index_name = \"medium\"\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    print(\"Creating index...\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=4096,\n",
    "        metric=\"cosine\",\n",
    "        spec=pinecone.PodSpec(\n",
    "            environment=\"gcp-starter\"\n",
    "        )\n",
    "    )\n",
    "    print(\"Creating Done!!\")\n",
    "else:\n",
    "    print(f'The index: {index_name} is already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the document\n",
    "vector_store = Pinecone.from_documents(\n",
    "    documents=chucks,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_retrieved = Pinecone.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asking Questions (Similarity Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I’ve also previously written about Polars\"\n",
    "response = vector_store.similarity_search(query, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a bold move that accelerates the pace of\n",
      "artificial intelligence development, Modular…\n",
      "Apr 3094 6.6K 124\n",
      "Hayk Simonyan Level Up Coding\n",
      "3.3K 20\n",
      "Thomas Reid AI Advances\n",
      "326 1\n",
      "Vishal Rajput AIGuys\n",
      "3.4K 33\n",
      "Elshad Karimov Stackademic\n",
      "305 26/25/24, 2:48 PM Python libraries take the Billion Row Challenge | by Thomas Reid | Level Up Coding\n",
      "https://medium.com/gitconnected/python-libraries-take-the-billion-row-challenge-7c108611a9ad 11/12\n",
      "Coding & Development\n",
      "11 stories·666 savesPredictive Modeling w/\n",
      "Python\n",
      "20 stories·1319 saves\n",
      "Practical Guides to Machine\n",
      "Learning\n",
      "10 stories·1586 savesChatGPT\n",
      "21 stories·688 saves\n",
      "See more recomme ndations\n",
      "How DuckDB can be up to 1000x\n",
      "more efficient than BigQuery?\n",
      "--------------------------------------------------\n",
      "Open in app\n",
      "Search Write\n",
      "6/25/24, 2:48 PM Python libraries take the Billion Row Challenge | by Thomas Reid | Level Up Coding\n",
      "https://medium.com/gitconnected/python-libraries-take-the-billion-row-challenge-7c108611a9ad 1/12\n",
      "Update Jan 4: Wow, this thing really took off!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for page in response:\n",
    "    print(page.page_content)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\", temperature=1)\n",
    "retriever = vector_store_retrieved.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What is the tools that is fastest processing the data?\"\n",
    "query = \"What the results of processing the data?\"\n",
    "response = chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the text, the results were:\n",
      "\n",
      "* DuckDB: 0 minutes 23 seconds\n",
      "* Datatable: 2 minutes 07 seconds\n",
      "* Polars: 2 minutes 30 seconds\n",
      "* Modin: 2 minutes 47 seconds\n",
      "* Pandas: 7 minutes 18 seconds\n",
      "* Vaex: 7 minutes 59 seconds\n"
     ]
    }
   ],
   "source": [
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
